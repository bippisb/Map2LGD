{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#from pg_utils_fn import create_block_mapped_dataset, fetch_block_mapping, populate_entity_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "\n",
    "def create_block_mapped_dataset(dataset, mapping):\n",
    "    \"\"\"\n",
    "    Create a mapped dataset by associating block codes with block names in the dataset.\n",
    "    \"\"\"\n",
    "    dataset['block_name'] = dataset['block_name'].str.strip()\n",
    "    dataset['block_code'] = dataset['block_name'].str.lower().map(mapping)\n",
    "    dataset.loc[dataset['block_code'].isnull(), 'block_code'] = -2\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def fetch_block_mapping():\n",
    "    \"\"\"\n",
    "    Fetch the block mapping from the SQLite database.\n",
    "\n",
    "    Returns:\n",
    "    - A list of tuples containing the block entity name, LGD code, name variants, and parent entity.\n",
    "    \"\"\"\n",
    "    # Connect to the SQLite database\n",
    "    conn = sqlite3.connect('lgd_database.db')\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Retrieve block data from the 'blocks' table\n",
    "    cursor.execute(\"SELECT entityName, entityLGDCode, entityNameVariants, entityParent FROM block\")\n",
    "    data = cursor.fetchall()\n",
    "\n",
    "    # Close the database connection\n",
    "    conn.close()\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "def populate_entity_mapping_without_parent(data,column_name,parent_column_name):\n",
    "    \"\"\"\n",
    "    Populates a entity mapping dictionary using data from a database and a local file.\n",
    "\n",
    "    Returns:\n",
    "        A defaultdict containing the mapping of entity names to their respective codes.\n",
    "    \"\"\"\n",
    "    # Load unique entity data\n",
    "    state_dataset = pd.read_csv('data.csv')\n",
    "    unique_rows = state_dataset.drop_duplicates(subset=[column_name])\n",
    "    unique_rows_lower = unique_rows.apply(lambda x: (x[column_name].strip().lower(), x[parent_column_name]), axis=1).tolist()\n",
    "\n",
    "    entity_mapping = {}\n",
    "    for entity_name, entity_code, entity_variants, parent_code in data:\n",
    "        for row in unique_rows_lower:\n",
    "            entity_name_lower = row[0]\n",
    "            state_code = row[1]\n",
    "            if entity_name_lower.strip() == entity_name.strip().lower():\n",
    "                entity_mapping[entity_name_lower] = entity_code\n",
    "                #print(entity_name_lower)\n",
    "            else:\n",
    "                if entity_variants:\n",
    "                    for variant in entity_variants.split(','):\n",
    "                        if variant.strip().lower() == entity_name_lower.strip():\n",
    "                            entity_mapping[variant.strip().lower()] = entity_code\n",
    "                            print(variant.strip().lower())\n",
    "\n",
    "    return entity_mapping\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'district_code'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\31658\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\31658\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\31658\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'district_code'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\databackup\\databackup\\MY_Scripts\\LGD\\BIPP\\CodeYatra\\test.ipynb Cell 3\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/databackup/databackup/MY_Scripts/LGD/BIPP/CodeYatra/test.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m data \u001b[39m=\u001b[39m fetch_block_mapping()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/databackup/databackup/MY_Scripts/LGD/BIPP/CodeYatra/test.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Apply block mapping and create a new dataset\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/databackup/databackup/MY_Scripts/LGD/BIPP/CodeYatra/test.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m block_mapping \u001b[39m=\u001b[39m populate_entity_mapping_without_parent(data,\u001b[39m'\u001b[39;49m\u001b[39mblock_name\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mdistrict_code\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/databackup/databackup/MY_Scripts/LGD/BIPP/CodeYatra/test.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m mapped_dataset \u001b[39m=\u001b[39m create_block_mapped_dataset(block_dataset, block_mapping)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/databackup/databackup/MY_Scripts/LGD/BIPP/CodeYatra/test.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Check if there are any unmatched names\u001b[39;00m\n",
      "\u001b[1;32md:\\databackup\\databackup\\MY_Scripts\\LGD\\BIPP\\CodeYatra\\test.ipynb Cell 3\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/databackup/databackup/MY_Scripts/LGD/BIPP/CodeYatra/test.ipynb#W2sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m state_dataset \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mdata.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/databackup/databackup/MY_Scripts/LGD/BIPP/CodeYatra/test.ipynb#W2sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m unique_rows \u001b[39m=\u001b[39m state_dataset\u001b[39m.\u001b[39mdrop_duplicates(subset\u001b[39m=\u001b[39m[column_name])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/databackup/databackup/MY_Scripts/LGD/BIPP/CodeYatra/test.ipynb#W2sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m unique_rows_lower \u001b[39m=\u001b[39m unique_rows\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: (x[column_name]\u001b[39m.\u001b[39;49mstrip()\u001b[39m.\u001b[39;49mlower(), x[parent_column_name]), axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/databackup/databackup/MY_Scripts/LGD/BIPP/CodeYatra/test.ipynb#W2sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m entity_mapping \u001b[39m=\u001b[39m {}\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/databackup/databackup/MY_Scripts/LGD/BIPP/CodeYatra/test.ipynb#W2sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39mfor\u001b[39;00m entity_name, entity_code, entity_variants, parent_code \u001b[39min\u001b[39;00m data:\n",
      "File \u001b[1;32mc:\\Users\\31658\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:9423\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   9412\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[0;32m   9414\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[0;32m   9415\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   9416\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9421\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[0;32m   9422\u001b[0m )\n\u001b[1;32m-> 9423\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\31658\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\apply.py:678\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[0;32m    676\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[1;32m--> 678\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\31658\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\apply.py:798\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    797\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 798\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[0;32m    800\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[0;32m    801\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32mc:\\Users\\31658\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\apply.py:814\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    812\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[0;32m    813\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 814\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[0;32m    815\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    816\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    817\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    818\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;32md:\\databackup\\databackup\\MY_Scripts\\LGD\\BIPP\\CodeYatra\\test.ipynb Cell 3\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/databackup/databackup/MY_Scripts/LGD/BIPP/CodeYatra/test.ipynb#W2sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m state_dataset \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mdata.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/databackup/databackup/MY_Scripts/LGD/BIPP/CodeYatra/test.ipynb#W2sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m unique_rows \u001b[39m=\u001b[39m state_dataset\u001b[39m.\u001b[39mdrop_duplicates(subset\u001b[39m=\u001b[39m[column_name])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/databackup/databackup/MY_Scripts/LGD/BIPP/CodeYatra/test.ipynb#W2sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m unique_rows_lower \u001b[39m=\u001b[39m unique_rows\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: (x[column_name]\u001b[39m.\u001b[39mstrip()\u001b[39m.\u001b[39mlower(), x[parent_column_name]), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/databackup/databackup/MY_Scripts/LGD/BIPP/CodeYatra/test.ipynb#W2sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m entity_mapping \u001b[39m=\u001b[39m {}\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/databackup/databackup/MY_Scripts/LGD/BIPP/CodeYatra/test.ipynb#W2sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39mfor\u001b[39;00m entity_name, entity_code, entity_variants, parent_code \u001b[39min\u001b[39;00m data:\n",
      "File \u001b[1;32mc:\\Users\\31658\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\series.py:1007\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1004\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[0;32m   1006\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1007\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[0;32m   1009\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m   1010\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1012\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\31658\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\series.py:1116\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1113\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[0;32m   1115\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1116\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[0;32m   1118\u001b[0m \u001b[39mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1119\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32mc:\\Users\\31658\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'district_code'"
     ]
    }
   ],
   "source": [
    "\n",
    "block_dataset = pd.read_csv('data.csv')\n",
    "data = fetch_block_mapping()\n",
    "# Apply block mapping and create a new dataset\n",
    "block_mapping = populate_entity_mapping_without_parent(data,'block_name','district_code')\n",
    "mapped_dataset = create_block_mapped_dataset(block_dataset, block_mapping)\n",
    "# Check if there are any unmatched names\n",
    "unmatched_names = mapped_dataset[mapped_dataset['block_code'] == -2]['block_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read the spreadsheet into a DataFrame\n",
    "df = pd.read_csv('unmapped_subset.csv')\n",
    "\n",
    "# Group the data by 'Block' and check for multiple 'Districts'\n",
    "block_counts = df.groupby('block_name')['district_name'].nunique()\n",
    "\n",
    "# Get the Blocks with multiple Districts\n",
    "blocks_with_multiple_districts = block_counts[block_counts > 1].index.tolist()\n",
    "\n",
    "result_dict = {}\n",
    "if len(blocks_with_multiple_districts) > 0:\n",
    "    for block in blocks_with_multiple_districts:\n",
    "        districts = ', '.join(df[df['block_name'] == block]['district_name'].unique())\n",
    "        result_dict[block] = districts\n",
    "\n",
    "# Create a DataFrame from the result_dict\n",
    "result_df = pd.DataFrame(result_dict.items(), columns=['Block', 'Districts'])\n",
    "\n",
    "# Save the resulting DataFrame to a CSV file\n",
    "result_df.to_csv('blocks_with_multiple_districts.csv', index=False)\n",
    "\n",
    "# Read the two Excel files\n",
    "df2 = pd.read_csv('blocks_with_multiple_districts.csv')\n",
    "df1 = pd.read_csv('data.csv')\n",
    "\n",
    "df1['block_name'] = df1['block_name'].str.lower()\n",
    "df2['block_name'] = df2['block_name'].str.lower()\n",
    "\n",
    "common_values = df1[~df1['block_name'].isin(df2['block_name'])]\n",
    "#merged = df1.merge(df2, on='block_name', how='left', indicator=True)\n",
    "#df1_unique = merged[merged['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "\n",
    "common_values.to_csv('output_sheet.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
